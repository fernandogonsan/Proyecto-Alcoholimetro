import sys
import time
import numpy as np
import cv2
import dlib
import json
import os
from math import hypot
from scipy import stats

# ======================
# CONFIGURACIÓN INICIAL
# ======================

PRUEBA_FINAL_DURACION = 30
BASELINE_FILE = os.path.join(os.path.dirname(__file__), "user_baseline.json") if "__file__" in globals() else "user_baseline.json"

# ======================
# INICIALIZACIÓN DE MODELOS
# ======================

detector = dlib.get_frontal_face_detector()
predictor = dlib.shape_predictor("/home/fernando/Documentos/tesis/shape_predictor_68_face_landmarks.dat")

cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("Error: No se pudo abrir la cámara")
    sys.exit(1)

# ======================
# FUNCIONES AUXILIARES
# ======================

def midpoint(p1, p2):
    return int((p1.x + p2.x)/2), int((p1.y + p2.y)/2)

def get_vertical_movement(landmarks, ref_y):
    return landmarks.part(30).y - ref_y

def calibrate_baseline():
    ear_values = []
    nose_positions = []
    face_widths = []
    start_time = time.time()

    cv2.namedWindow("Calibración", cv2.WINDOW_NORMAL)

    print("\n=== MODO CALIBRACIÓN ===")
    print("Por favor mire directamente a la cámara")
    print("Mantenga una expresión neutral durante 30 segundos\n")

    while (time.time() - start_time) < PRUEBA_FINAL_DURACION:
        ret, frame = cap.read()
        if not ret: continue

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = detector(gray)

        if len(faces) > 0:
            landmarks = predictor(gray, faces[0])
            left_ear = get_blinking_ratio([36, 37, 38, 39, 40, 41], landmarks)
            right_ear = get_blinking_ratio([42, 43, 44, 45, 46, 47], landmarks)
            ear_values.append((left_ear + right_ear)/2)
            nose_positions.append(landmarks.part(30).y)
            face_widths.append(abs(landmarks.part(16).x - landmarks.part(0).x))

        frame_display = frame.copy()
        tiempo_restante = PRUEBA_FINAL_DURACION - int(time.time() - start_time)
        cv2.putText(frame_display, f"CALIBRANDO: {tiempo_restante}s",
                   (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0,255,0), 2)
        cv2.imshow("Calibración", frame_display)

        if cv2.waitKey(1) == 27:
            break

    cv2.destroyWindow("Calibración")

    if ear_values and nose_positions:
        ear_values = stats.trimboth(ear_values, 0.1)
        nose_positions = stats.trimboth(nose_positions, 0.1)

        baseline_data = {
            'baseline_ear': float(np.mean(ear_values)),
            'baseline_nose_y': float(np.mean(nose_positions)),
            'face_width_ref': float(np.mean(face_widths)),
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S")
        }
        print("\nCalibración completada exitosamente!")
        print(f"EAR de referencia: {baseline_data['baseline_ear']:.2f}")
        print(f"Posición nariz referencia: {baseline_data['baseline_nose_y']:.1f}")
        print(f"Ancho de cara referencia: {baseline_data['face_width_ref']:.1f} px\n")

        try:
            with open(BASELINE_FILE, 'w') as f:
                json.dump(baseline_data, f, indent=4)
            print(f"Datos guardados en: {BASELINE_FILE}")
        except Exception as e:
            print(f"Error guardando archivo: {str(e)}")

        return baseline_data
    else:
        print("\nAdvertencia: No se detectaron rostros durante la calibración")
        return {
            'baseline_ear': 5.6,
            'baseline_nose_y': 0,
            'face_width_ref': 100,
            'timestamp': "N/A"
        }

def realizar_prueba_final(baseline_data, duracion=30):
    print("\n=== PRUEBA FINAL DE CONDICIÓN ===")
    print(f"Duración de la prueba: {duracion} segundos")
    print("Mantente mirando al frente con una expresión neutral...\n")

    conteo_parpadeo = 0
    conteo_cabeceo = 0
    parpadeo_anterior = False
    moving_down = False
    start_time = time.time()

    while (time.time() - start_time) < duracion:
        ret, frame = cap.read()
        if not ret: continue

        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = detector(gray)
        rostro_detectado = len(faces) > 0
        current_ear = baseline_data['baseline_ear']

        if rostro_detectado:
            landmarks = predictor(gray, faces[0])
            current_face_width = abs(landmarks.part(16).x - landmarks.part(0).x)
            scale_factor = baseline_data['face_width_ref'] / current_face_width

            vertical_movement = get_vertical_movement(landmarks, baseline_data['baseline_nose_y']) * scale_factor
            if vertical_movement > 6 and not moving_down:
                moving_down = True
            elif vertical_movement < -6 and moving_down:
                conteo_cabeceo += 1
                moving_down = False

            blinking_ratio = (get_blinking_ratio([36,37,38,39,40,41], landmarks) +
                              get_blinking_ratio([42,43,44,45,46,47], landmarks)) / 2
            current_ear = blinking_ratio

            if blinking_ratio > baseline_data['baseline_ear'] * 0.8:
                if not parpadeo_anterior:
                    conteo_parpadeo += 1
                    parpadeo_anterior = True
            else:
                parpadeo_anterior = False

        frame_display = frame.copy()
        estado = "ROSTRO DETECTADO" if rostro_detectado else "SIN ROSTRO"
        cv2.putText(frame_display, estado, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7,
                    (0,255,0) if rostro_detectado else (0,0,255), 2)
        cv2.putText(frame_display, f"Parpadeos: {conteo_parpadeo}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)
        cv2.putText(frame_display, f"Cabeceos: {conteo_cabeceo}", (10, 90),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1)
        tiempo_restante = duracion - int(time.time() - start_time)
        cv2.putText(frame_display, f"Tiempo restante: {tiempo_restante}s", (10, 120),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,0), 1)

        cv2.imshow("Prueba Final", frame_display)
        if cv2.waitKey(1) == 27:
            break

    cv2.destroyWindow("Prueba Final")

    ppm = (conteo_parpadeo / duracion) * 60
    cpm = (conteo_cabeceo / duracion) * 60

    print(f"\n--- RESULTADOS PRUEBA FINAL ---")
    print(f"Parpadeos por minuto (PPM): {ppm:.1f}")
    print(f"Cabeceos por minuto (CPM): {cpm:.1f}")

    if ppm > baseline_data['baseline_ear'] * 1.5 or cpm > 5:
        print(" Resultado: No estás en condiciones de continuar (posible fatiga)")
    else:
        print(" Resultado: Puedes continuar con normalidad")


print("\nIniciando sistema de detección de fatiga...")

start_time = time.time()
while time.time() - start_time < 3:
    ret, frame = cap.read()
    if not ret: continue
    cv2.putText(frame, "INICIANDO SISTEMA...",
                (frame.shape[1]//2 - 200, frame.shape[0]//2),
                cv2.FONT_HERSHEY_DUPLEX, 1, (255,255,255), 2)
    cv2.imshow("Inicio", frame)
    if cv2.waitKey(1) == 27:
        cap.release()
        cv2.destroyAllWindows()
        sys.exit()
cv2.destroyWindow("Inicio")

# Reconocimiento facial
print("\n=== MODO RECONOCIMIENTO ===")
recognized = False
recognized_name = "Usuario no reconocido"

while not recognized:
    ret, frame = cap.read()
    if not ret: continue

    face_locations, face_names = sfr.detect_known_faces(frame)
    if face_names:
        for name in face_names:
            if name != "Unknown":
                recognized_name = f"Bienvenido, {name}"
                recognized = True

    frame_display = frame.copy()
    cv2.putText(frame_display, "Reconociendo usuario...",
                (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)
    cv2.imshow("Reconocimiento", frame_display)
    if cv2.waitKey(1) == 27 or recognized:
        break

cv2.destroyWindow("Reconocimiento")

# Calibración
print("\n=== CONFIGURACIÓN DE CALIBRACIÓN ===")
try:
    with open(BASELINE_FILE, 'r') as f:
        baseline_data = json.load(f)
    print("Datos de calibración cargados exitosamente")
except (FileNotFoundError, json.JSONDecodeError):
    baseline_data = calibrate_baseline()
    with open(BASELINE_FILE, 'w') as f:
        json.dump(baseline_data, f, indent=4)

realizar_prueba_final(baseline_data)

cap.release()
cv2.destroyAllWindows()
print("Programa terminado correctamente.")
